{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "# !pip install --upgrade typing_extensions\n",
        "# !pip uninstall typing_extensions\n",
        "# !pip install typing_extensions\n",
        "\n",
        "# !pip install typing_extensions"
      ],
      "metadata": {
        "id": "GftT_AvMggsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "from openai import OpenAI\n",
        "openai = OpenAI(api_key = \"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\")\n",
        "def chat_with_customer(api_key):\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    start_sequence = \"\\nAI:\"\n",
        "    restart_sequence = \"\\nHuman: \"\n",
        "\n",
        "    session_prompt = \"You are a helpful assistant. Please collect the customer's name, age, email ,postcode, name of products. assing order time for each costumer. Then confirm if the information is correct.\"\n",
        "\n",
        "    customer_data = []\n",
        "\n",
        "    for _ in range(4):  # Interact with 4 customers\n",
        "        messages = []\n",
        "        message = {\"role\": \"system\", \"content\": session_prompt}\n",
        "        confirmed = False\n",
        "\n",
        "        while not confirmed:\n",
        "            messages.append(message)\n",
        "            prompt = \"\".join([message['content'] for message in messages])\n",
        "            response = openai.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=messages,\n",
        "\n",
        "                max_tokens=150,\n",
        "                temperature=0.7,\n",
        "                stop=[\"Human:\", \"AI:\"],\n",
        "                n=1,\n",
        "                logprobs=None,\n",
        "            )\n",
        "\n",
        "            message = {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": start_sequence + response.choices[0].message.content\n",
        "            }\n",
        "            print(message[\"content\"])\n",
        "\n",
        "            user_input = input(\"Human: \")\n",
        "            message = {\"role\": \"user\", \"content\": restart_sequence + user_input}\n",
        "\n",
        "            if \"yes\" in user_input.lower():\n",
        "                confirmed = True\n",
        "                customer_data.append(prompt + response.choices[0].message.content)\n",
        "            elif \"no\" in user_input.lower():\n",
        "                print(\"Let's try again.\")\n",
        "                break\n",
        "\n",
        "    return customer_data\n",
        "\n",
        "# Example usage\n",
        "api_key = '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'\n",
        "all_customer_data = chat_with_customer(api_key)\n",
        "\n",
        "with open('customer_data.txt', 'w') as file:\n",
        "    for data in all_customer_data:\n",
        "        file.write(data)\n",
        "\n",
        "print(\"All customer data has been saved to customer_data.txt\")\n"
      ],
      "metadata": {
        "id": "jrvq-iWrY4FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "from openai import OpenAI\n",
        "openai = OpenAI(api_key = \"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\")\n",
        "def extract_info_with_llm(text, api_key, model=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Uses an LLM to extract information from the provided text.\n",
        "    The model argument specifies which LLM model to use.\n",
        "    \"\"\"\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    try:\n",
        "        # response = openai.chat.completions.create(\n",
        "        #     model=model,\n",
        "        #     prompt=f\"Extract and structure the following information as JSON: {text}\",\n",
        "        #     max_tokens=100  # Adjust as needed\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": 'You are a program that transforms user input to JSON .assing order time for each also  '},\n",
        "                {\"role\": \"assistant\", \"content\": 'Name , Age , Email,postcode,products,order time'},\n",
        "                {\"role\": \"user\", \"content\": f\"{text}\"},\n",
        "\n",
        "\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "        parsed_data = json.loads(response.choices[0].message.content)\n",
        "        return parsed_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error in LLM response: {e}\")\n",
        "        return None\n",
        "\n",
        "def save_to_json(data, json_file_path):\n",
        "    with open(json_file_path, 'w', encoding='utf-8') as file:\n",
        "        json.dump(data, file, indent=2)\n",
        "\n",
        "# Example usage\n",
        "api_key = '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'\n",
        "file_path='/content/customer_data.txt'\n",
        "json_file_path = 'output.json'\n",
        "def process_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        paragraphs = file.read().split('\\n')\n",
        "\n",
        "    parsed_data = []\n",
        "    for paragraph in paragraphs:\n",
        "      parsed_data.append(extract_info_with_llm(paragraph, api_key))\n",
        "    return parsed_data\n",
        "\n",
        "parsed_data = process_file(file_path)\n",
        "save_to_json(parsed_data, json_file_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "48uZCimu0RGw"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}